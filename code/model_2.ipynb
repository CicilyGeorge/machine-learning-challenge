{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T19:21:23.983893Z",
     "start_time": "2021-02-06T19:21:22.358156Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%run preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Function for Random Forest and Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T19:21:32.101156Z",
     "start_time": "2021-02-06T19:21:31.981222Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_params = {\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=0),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,10,50,70]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T19:21:44.744623Z",
     "start_time": "2021-02-06T19:21:34.453662Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 model  best_score           best_params\n",
       "0        random_forest    0.895202  {'n_estimators': 70}\n",
       "1  logistic_regression    0.820990              {'C': 5}"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>best_score</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random_forest</td>\n      <td>0.895202</td>\n      <td>{'n_estimators': 70}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>logistic_regression</td>\n      <td>0.820990</td>\n      <td>{'C': 5}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "result_df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above, I can conclude that Random Forest with n_estimators=70 is the best model for solving my problem of Exoplanet classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T19:22:15.816223Z",
     "start_time": "2021-02-06T19:22:14.837499Z"
    }
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=70)\n",
    "model_rf = model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T19:22:20.052580Z",
     "start_time": "2021-02-06T19:22:19.892617Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model_rf.sav']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'model_rf.sav'\n",
    "joblib.dump(model_rf, filename)"
   ]
  },
  {
   "source": [
    "# Evaluate the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                precision    recall  f1-score   support\n\n     CONFIRMED       0.81      0.79      0.80       327\nFALSE POSITIVE       0.85      0.82      0.83       393\n     CANDIDATE       0.97      1.00      0.98       679\n\n      accuracy                           0.90      1399\n     macro avg       0.88      0.87      0.87      1399\n  weighted avg       0.90      0.90      0.90      1399\n\n"
     ]
    }
   ],
   "source": [
    "# load the trained model from saved file\n",
    "model_clf = joblib.load(filename)\n",
    "\n",
    "\n",
    "# Make predictions with the model\n",
    "predictions = model_clf.predict(X_test)\n",
    "\n",
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"CONFIRMED\", \"FALSE POSITIVE\", \"CANDIDATE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}